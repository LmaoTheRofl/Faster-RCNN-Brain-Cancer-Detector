{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuUB_GQjckT0"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMWW8oX6cYnp"
      },
      "outputs": [],
      "source": [
        "HERE = Path(_dh[-1])\n",
        "DATA = HERE / \"data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB8i-GKuckoc",
        "outputId": "3a105423-5fe5-4ada-9745-6ce73d7ffb00"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle\n",
        "!pip install kagglehub[pandas-datasets]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOxVuEWTc_Y6",
        "outputId": "930f85aa-5eb9-4426-9660-43e97a456907"
      },
      "outputs": [],
      "source": [
        "!kaggle --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHyELhWddC9i",
        "outputId": "b568814f-0a69-44cb-83ec-ec13a15e3a86"
      },
      "outputs": [],
      "source": [
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7x_iASYV4zz1",
        "outputId": "ec160852-df10-417c-8139-c29cd6891b17"
      },
      "outputs": [],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgMUHjmpj7-9",
        "outputId": "43c01f96-21a1-499e-f200-7bc7e09a9b9e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(torch.version.cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbUlpUFxZmOc",
        "outputId": "1b88dcd4-3460-42a7-c808-f1e36d421f34"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEvYSiNDMBaa",
        "outputId": "8823f483-0a6c-4682-d140-f5733ad83eb5"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2, FasterRCNN_ResNet50_FPN_V2_Weights\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.io import read_image\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import torchvision.ops as ops\n",
        "import cv2\n",
        "from torchvision.ops import box_iou\n",
        "import json\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_recall_curve, average_precision_score\n",
        "import plotly.graph_objs as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "print(\"PyTorch:\", torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tS26Chs8jjGS"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH2RygHqK8gR",
        "outputId": "f2481a1b-6a9d-41bf-f22b-734fc02c3d8f"
      },
      "outputs": [],
      "source": [
        "path = kagglehub.dataset_download(\"ahmedhamada0/brain-tumor-detection\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDAvhgIbYfAL"
      },
      "outputs": [],
      "source": [
        "class BrainCancerDetectionDataset(Dataset):\n",
        "    def __init__(self, json_file, root_dir, transform=None, image_size=(256, 256)):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_size = image_size\n",
        "\n",
        "        with open(json_file, 'r') as f:\n",
        "            self.data = json.load(f)\n",
        "\n",
        "        self.image_keys = list(self.data.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        key = self.image_keys[idx]\n",
        "        image_info = self.data[key]\n",
        "        file_name = image_info['filename']\n",
        "        file_path = os.path.join(self.root_dir, file_name)\n",
        "\n",
        "        image = Image.open(file_path).convert('RGB')\n",
        "        original_size = image.size\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        else:\n",
        "            image = transforms.functional.resize(image, self.image_size)\n",
        "            image = transforms.functional.to_tensor(image)\n",
        "\n",
        "        mask = np.zeros((original_size[1], original_size[0]), dtype=np.uint8)\n",
        "        for region in image_info['regions']:\n",
        "            shape_attributes = region['shape_attributes']\n",
        "            if shape_attributes['name'] == 'polygon':\n",
        "                points_x = shape_attributes['all_points_x']\n",
        "                points_y = shape_attributes['all_points_y']\n",
        "                points = np.array(list(zip(points_x, points_y)), dtype=np.int32)\n",
        "                cv2.fillPoly(mask, [points], 1)\n",
        "            elif shape_attributes['name'] == 'ellipse':\n",
        "                center_x = int(shape_attributes['cx'])\n",
        "                center_y = int(shape_attributes['cy'])\n",
        "                radius_x = int(shape_attributes['rx'])\n",
        "                radius_y = int(shape_attributes['ry'])\n",
        "                angle = shape_attributes.get('theta', 0) * (180.0 / np.pi)\n",
        "                cv2.ellipse(mask, (center_x, center_y), (radius_x, radius_y), angle, 0, 360, 1, -1)\n",
        "\n",
        "        mask_resized = cv2.resize(mask, self.image_size, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        num_labels, labels_im, stats, _ = cv2.connectedComponentsWithStats(mask_resized, connectivity=8)\n",
        "        boxes = []\n",
        "        labels = []\n",
        "\n",
        "        for i in range(1, num_labels):\n",
        "            x, y, w, h = stats[i][:4]\n",
        "            boxes.append([x, y, x + w, y + h])\n",
        "            labels.append(1)\n",
        "\n",
        "        if not boxes:\n",
        "            boxes = [[0, 0, 1, 1]]\n",
        "            labels = [0]\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "\n",
        "        targets = {\n",
        "            'boxes': boxes,\n",
        "            'labels': labels,\n",
        "            'masks': torch.as_tensor(mask_resized > 0, dtype=torch.uint8)\n",
        "        }\n",
        "\n",
        "        return image, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASX82a0qY48p"
      },
      "outputs": [],
      "source": [
        "train_root_dir = '/kaggle/input/brain-tumor-detection/Br35H-Mask-RCNN/TRAIN'\n",
        "train_json_file = os.path.join(train_root_dir, \"/kaggle/input/brain-tumor-detection/Br35H-Mask-RCNN/TRAIN/annotations_train.json\")\n",
        "val_root_dir = '/kaggle/input/brain-tumor-detection/Br35H-Mask-RCNN/VAL'\n",
        "val_json_file = os.path.join(val_root_dir, \"/kaggle/input/brain-tumor-detection/Br35H-Mask-RCNN/VAL/annotations_val.json\")\n",
        "test_root_dir = '/kaggle/input/brain-tumor-detection/Br35H-Mask-RCNN/TEST'\n",
        "test_json_file = os.path.join(test_root_dir, \"/kaggle/input/brain-tumor-detection/Br35H-Mask-RCNN/TEST/annotations_test.json\")\n",
        "\n",
        "train_dataset = BrainCancerDetectionDataset(train_json_file, train_root_dir, transform=None, image_size=(256, 256))\n",
        "val_dataset = BrainCancerDetectionDataset(val_json_file, val_root_dir, transform=None, image_size=(256, 256))\n",
        "test_dataset = BrainCancerDetectionDataset(test_json_file, test_root_dir, transform=None, image_size=(256, 256))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqKN7gzP3L5z"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKC05CMuowrj"
      },
      "outputs": [],
      "source": [
        "def visualize_predictions(dataset, model, device, num_images=2, score_threshold=0.3):\n",
        "    indices = random.sample(range(len(dataset)), num_images)\n",
        "    for idx in indices:\n",
        "        image, target = dataset[idx]\n",
        "        image = image.to(device)\n",
        "        with torch.no_grad():\n",
        "            prediction = model([image])[0]\n",
        "\n",
        "        img = image.cpu().permute(1, 2, 0).numpy()\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        plt.imshow(img)\n",
        "        ax = plt.gca()\n",
        "\n",
        "        # Реальные боксы\n",
        "        gt_boxes = target['boxes'].cpu().numpy()\n",
        "        gt_labels = target['labels'].cpu().numpy()\n",
        "        for box, label in zip(gt_boxes, gt_labels):\n",
        "            if label == 0:\n",
        "                continue\n",
        "            xmin, ymin, xmax, ymax = box\n",
        "            rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
        "                                 linewidth=2, edgecolor='g', facecolor='none', label='Реальный бокс')\n",
        "            ax.add_patch(rect)\n",
        "\n",
        "        # Предсказанные боксы\n",
        "        pred_boxes = prediction['boxes'].cpu().numpy()\n",
        "        pred_scores = prediction['scores'].cpu().numpy()\n",
        "        pred_labels = prediction['labels'].cpu().numpy()\n",
        "        for box, score, label in zip(pred_boxes, pred_scores, pred_labels):\n",
        "            if score >= score_threshold and label == 1:  # 1 класс\n",
        "                xmin, ymin, xmax, ymax = box\n",
        "                rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
        "                                     linewidth=2, edgecolor='r', facecolor='none')\n",
        "                ax.add_patch(rect)\n",
        "                ax.text(xmin, ymin, f\"{score:.2f}\", color='red', fontsize=8, backgroundcolor='white')\n",
        "\n",
        "        plt.title(\"Зеленый - реальные боксы; Красный - предсказаннные боксы\")\n",
        "        plt.axis('off')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6nm_f4-U_h_"
      },
      "outputs": [],
      "source": [
        "def compute_pr_curve(predictions, targets, iou_threshold=0.5, num_thresholds=50):\n",
        "    thresholds = np.linspace(0, 1, num_thresholds)\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "\n",
        "    for t in thresholds:\n",
        "        tp = 0\n",
        "        fp = 0\n",
        "        fn = 0\n",
        "\n",
        "        for pred, tgt in zip(predictions, targets):\n",
        "            gt_boxes = tgt['boxes']\n",
        "            gt_labels = tgt['labels']\n",
        "            valid_gt_mask = (gt_labels == 1)\n",
        "            gt_boxes = gt_boxes[valid_gt_mask]\n",
        "\n",
        "            pred_boxes = pred['boxes']\n",
        "            pred_scores = pred['scores']\n",
        "            pred_labels = pred['labels']\n",
        "            keep_mask = (pred_scores >= t) & (pred_labels == 1)\n",
        "            pred_boxes_t = pred_boxes[keep_mask]\n",
        "\n",
        "            matched_gt_indices = set()\n",
        "\n",
        "            if len(pred_boxes_t) > 0 and len(gt_boxes) > 0:\n",
        "                ious = box_iou(torch.tensor(pred_boxes_t), torch.tensor(gt_boxes))\n",
        "                for i in range(ious.shape[0]):\n",
        "                    max_iou, max_idx = torch.max(ious[i], dim=0)\n",
        "                    if max_iou >= iou_threshold:\n",
        "                        if max_idx.item() not in matched_gt_indices:\n",
        "                            tp += 1\n",
        "                            matched_gt_indices.add(max_idx.item())\n",
        "\n",
        "            fp += len(pred_boxes_t) - len(matched_gt_indices)\n",
        "            fn += len(gt_boxes) - len(matched_gt_indices)\n",
        "\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        precisions.append(precision)\n",
        "        recalls.append(recall)\n",
        "\n",
        "    return np.array(recalls), np.array(precisions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CelAWAQyDxNT"
      },
      "outputs": [],
      "source": [
        "def plot_pr_curve(recall, precision, epoch):\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=recall, y=precision, mode='lines', name=f'PR-кривая'))\n",
        "    fig.update_layout(title=f'PR-кривая - Epoch {epoch}', xaxis_title='Recall', yaxis_title='Precision')\n",
        "    fig.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyfwuI5Q0oSU"
      },
      "source": [
        "# Обучение не предобученной модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUUmobXZn0wZ"
      },
      "outputs": [],
      "source": [
        "device = 'cuda'\n",
        "num_epochs = 28\n",
        "num_classes = 2\n",
        "\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn_v2(pretrained=False)\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ylvJ-djJn58f",
        "outputId": "2989b3a9-cc5a-45da-9502-634b9e49b9b3"
      },
      "outputs": [],
      "source": [
        "history = {\n",
        "    'train_loss': [],\n",
        "    'val_recall': [],\n",
        "    'val_precision': []\n",
        "}\n",
        "for epoch in range(num_epochs):\n",
        "    # Обучение\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "        images, targets = batch\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_output = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_output.values())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += losses.item()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    history['train_loss'].append(avg_train_loss)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Training loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # Валидация\n",
        "    model.eval()\n",
        "\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for val_batch in tqdm(val_loader, desc=\"Validation\"):\n",
        "            val_images, val_targets = val_batch\n",
        "            val_images = [image.to(device) for image in val_images]\n",
        "            val_targets = [{k: v.to(device) for k, v in t.items()} for t in val_targets]\n",
        "\n",
        "            outputs = model(val_images)\n",
        "\n",
        "            for pred, tgt in zip(outputs, val_targets):\n",
        "                pred_box = pred['boxes'].cpu().numpy()\n",
        "                pred_score = pred['scores'].cpu().numpy()\n",
        "                pred_label = pred['labels'].cpu().numpy()\n",
        "\n",
        "                gt_box = tgt['boxes'].cpu().numpy()\n",
        "                gt_label = tgt['labels'].cpu().numpy()\n",
        "\n",
        "                all_predictions.append({\n",
        "                    'boxes': pred_box,\n",
        "                    'scores': pred_score,\n",
        "                    'labels': pred_label\n",
        "                })\n",
        "\n",
        "                all_targets.append({\n",
        "                    'boxes': gt_box,\n",
        "                    'labels': gt_label\n",
        "                })\n",
        "\n",
        "    # Построение кривой валидации на каждой эпохе\n",
        "    recall_list, precision_list = compute_pr_curve(all_predictions, all_targets, iou_threshold=0.5)\n",
        "\n",
        "    mean_recall = np.mean(recall_list)\n",
        "    mean_precision = np.mean(precision_list)\n",
        "\n",
        "    history['val_recall'].append(mean_recall)\n",
        "    history['val_precision'].append(mean_precision)\n",
        "\n",
        "    plot_pr_curve(recall_list, precision_list, epoch+1)\n",
        "\n",
        "    visualize_predictions(val_dataset, model, device, num_images=2, score_threshold=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "NapHtqKFnkWm",
        "outputId": "c91b69f1-2b33-4ecf-faeb-432e1f4d7961"
      },
      "outputs": [],
      "source": [
        "epochs = list(range(1, num_epochs + 1))\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# График потерь обучения loss\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=epochs,\n",
        "    y=history['train_loss'],\n",
        "    mode='lines+markers',\n",
        "    name='Train Loss'\n",
        "))\n",
        "\n",
        "# График Recall\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=epochs,\n",
        "    y=history['val_recall'],\n",
        "    mode='lines+markers',\n",
        "    name='Recall'\n",
        "))\n",
        "\n",
        "# График Precision\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=epochs,\n",
        "    y=history['val_precision'],\n",
        "    mode='lines+markers',\n",
        "    name='Precision'\n",
        "))\n",
        "\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Обучение и Валидация Метрик по эпохам',\n",
        "    xaxis_title='Эпоха',\n",
        "    yaxis_title='Значение',\n",
        "    legend=dict(\n",
        "        x=0,\n",
        "        y=1.0,\n",
        "        bgcolor='rgba(255,255,255,0)',\n",
        "        bordercolor='rgba(255,255,255,0)'\n",
        "    ),\n",
        "    margin=dict(l=40, r=40, t=80, b=40)\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRaLzs9tsDcR",
        "outputId": "be124f11-428d-4421-86e3-6997345cd375"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'fasterrcnn_brain_tumor_detection_v1.pth')\n",
        "print(\"Модель сохранена как fasterrcnn_brain_tumor_detection_v1.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHhwfLTv0xyV"
      },
      "source": [
        "# Тест"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UATtdvyL-qPu",
        "outputId": "0cb8bb95-5e27-49d7-cddc-a43dca6f1cc7"
      },
      "outputs": [],
      "source": [
        "device = 'cuda'\n",
        "model_path = '/content/fasterrcnn_brain_tumor_detection_v1.pth'\n",
        "num_classes = 2\n",
        "\n",
        "model = fasterrcnn_resnet50_fpn_v2(pretrained=False)\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "visualize_predictions(test_dataset, model, device, num_images=5, score_threshold=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z81KcDyl06wh"
      },
      "source": [
        "# Обучение предобученной модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43lsznMYNtBZ",
        "outputId": "69aae5a4-2d5c-4902-ac54-82e1e0d21e03"
      },
      "outputs": [],
      "source": [
        "device = 'cuda'\n",
        "num_epochs = 20\n",
        "num_classes = 2\n",
        "\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn_v2(pretrained=True)\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "# for param in model.parameters():\n",
        "#     param.requires_grad = True\n",
        "\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0LhMyfLNksVd",
        "outputId": "537753de-34b3-4446-b73c-18e39adc0bc9"
      },
      "outputs": [],
      "source": [
        "history = {\n",
        "    'train_loss': [],\n",
        "    'val_recall': [],\n",
        "    'val_precision': []\n",
        "}\n",
        "for epoch in range(num_epochs):\n",
        "    # Обучение\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "        images, targets = batch\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_output = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_output.values())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += losses.item()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    history['train_loss'].append(avg_train_loss)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Training loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # Валидация\n",
        "    model.eval()\n",
        "\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for val_batch in tqdm(val_loader, desc=\"Validation\"):\n",
        "            val_images, val_targets = val_batch\n",
        "            val_images = [image.to(device) for image in val_images]\n",
        "            val_targets = [{k: v.to(device) for k, v in t.items()} for t in val_targets]\n",
        "\n",
        "            outputs = model(val_images)\n",
        "\n",
        "            for pred, tgt in zip(outputs, val_targets):\n",
        "                pred_box = pred['boxes'].cpu().numpy()\n",
        "                pred_score = pred['scores'].cpu().numpy()\n",
        "                pred_label = pred['labels'].cpu().numpy()\n",
        "\n",
        "                gt_box = tgt['boxes'].cpu().numpy()\n",
        "                gt_label = tgt['labels'].cpu().numpy()\n",
        "\n",
        "                all_predictions.append({\n",
        "                    'boxes': pred_box,\n",
        "                    'scores': pred_score,\n",
        "                    'labels': pred_label\n",
        "                })\n",
        "\n",
        "                all_targets.append({\n",
        "                    'boxes': gt_box,\n",
        "                    'labels': gt_label\n",
        "                })\n",
        "\n",
        "    # Построение кривой валидации на каждой эпохе\n",
        "    recall_list, precision_list = compute_pr_curve(all_predictions, all_targets, iou_threshold=0.5)\n",
        "\n",
        "    mean_recall = np.mean(recall_list)\n",
        "    mean_precision = np.mean(precision_list)\n",
        "\n",
        "    history['val_recall'].append(mean_recall)\n",
        "    history['val_precision'].append(mean_precision)\n",
        "\n",
        "    plot_pr_curve(recall_list, precision_list, epoch+1)\n",
        "\n",
        "    visualize_predictions(val_dataset, model, device, num_images=2, score_threshold=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "O9NEn-9cxCeI",
        "outputId": "36ce5755-8d38-42f6-e5d7-9ead24dcb34d"
      },
      "outputs": [],
      "source": [
        "epochs = list(range(1, num_epochs + 1))\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# График потерь обучения loss\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=epochs,\n",
        "    y=history['train_loss'],\n",
        "    mode='lines+markers',\n",
        "    name='Train Loss'\n",
        "))\n",
        "\n",
        "# График Recall\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=epochs,\n",
        "    y=history['val_recall'],\n",
        "    mode='lines+markers',\n",
        "    name='Recall'\n",
        "))\n",
        "\n",
        "# График Precision\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=epochs,\n",
        "    y=history['val_precision'],\n",
        "    mode='lines+markers',\n",
        "    name='Precision'\n",
        "))\n",
        "\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Обучение и Валидация Метрик по эпохам',\n",
        "    xaxis_title='Эпоха',\n",
        "    yaxis_title='Значение',\n",
        "    legend=dict(\n",
        "        x=0,\n",
        "        y=1.0,\n",
        "        bgcolor='rgba(255,255,255,0)',\n",
        "        bordercolor='rgba(255,255,255,0)'\n",
        "    ),\n",
        "    margin=dict(l=40, r=40, t=80, b=40)\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aIVGo30lxVy",
        "outputId": "61366c44-5dd3-4de8-a306-f75f0b5ec245"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'fasterrcnn_brain_tumor_detection_v2.pth')\n",
        "print(\"Модель сохранена как fasterrcnn_brain_tumor_detection_v2.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2naeMFt0_-M"
      },
      "source": [
        "# Тест"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y0UHsh-q_SmF",
        "outputId": "f51b06f4-d80d-4f2a-acb3-4c7eb863f027"
      },
      "outputs": [],
      "source": [
        "device = 'cpu'\n",
        "model_path = '/content/fasterrcnn_brain_tumor_detection_v2.pth'\n",
        "num_classes = 2\n",
        "\n",
        "model = fasterrcnn_resnet50_fpn_v2(pretrained=False)\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "visualize_predictions(test_dataset, model, device, num_images=5, score_threshold=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTPvjxZgxMO0",
        "outputId": "fc8bb621-db37-45c8-ea91-7486ffde6add"
      },
      "outputs": [],
      "source": [
        "import torchmetrics\n",
        "\n",
        "device = 'cpu'\n",
        "model_path = '/content/fasterrcnn_brain_tumor_detection_v2.pth'\n",
        "num_classes = 2\n",
        "\n",
        "model = fasterrcnn_resnet50_fpn_v2(pretrained=False)\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
        "model.to(device)\n",
        "\n",
        "precision_metric = torchmetrics.Precision(task='binary').to(device)\n",
        "recall_metric = torchmetrics.Recall(task='binary').to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, targets in val_loader:\n",
        "        images = [img.to(device) for img in images]\n",
        "        outputs = model(images)\n",
        "\n",
        "        for tgt, pred in zip(targets, outputs):\n",
        "            gt_labels = tgt['labels']\n",
        "            pred_scores = pred['scores']\n",
        "            threshold = 0.5\n",
        "            pred_labels = (pred_scores >= threshold).to(device)\n",
        "\n",
        "            pred_positive = int(pred_labels.any())\n",
        "\n",
        "            gt_positive = int((gt_labels == 1).any())\n",
        "\n",
        "            precision_metric.update(torch.tensor([pred_positive], device=device), torch.tensor([gt_positive], device=device))\n",
        "            recall_metric.update(torch.tensor([pred_positive], device=device), torch.tensor([gt_positive], device=device))\n",
        "\n",
        "precision = precision_metric.compute()\n",
        "recall = recall_metric.compute()\n",
        "\n",
        "print('Precision:', precision.item())\n",
        "print('Recall:', recall.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNUAAus85SBS"
      },
      "source": [
        "# Подбор гиперпараметров"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLohYIE_3vT5",
        "outputId": "41b5ced9-5166-4bee-9bce-dcc9799e1e5b"
      },
      "outputs": [],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCfwMdtj3yGn"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn, optim\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAaHr8YI8sYp"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jQ6Z8UwH2qSa",
        "outputId": "f03d0c70-bed6-4770-c053-b621ca3bd8a5"
      },
      "outputs": [],
      "source": [
        "device = 'cuda'\n",
        "def train_and_evaluate(trial):\n",
        "    # Гиперпараметры\n",
        "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
        "    batch_size = trial.suggest_categorical('batch_size', [2, 4])\n",
        "    num_epochs = 20\n",
        "    score_threshold = trial.suggest_uniform('score_threshold', 0.1, 0.5)\n",
        "    iou_threshold = 0.5\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
        "\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn_v2(pretrained=False)\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes=2)\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for images, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "            images = list(img.to(device) for img in images)\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            loss_dict = model(images, targets)\n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            losses.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += losses.item()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    # Валидация\n",
        "    model.eval()\n",
        "\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in tqdm(val_loader, desc=\"Validation\"):\n",
        "            images = [img.to(device) for img in images]\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            outputs = model(images)\n",
        "\n",
        "            for pred, tgt in zip(outputs, targets):\n",
        "                pred_box = pred['boxes'].cpu()\n",
        "                pred_score = pred['scores'].cpu()\n",
        "                pred_label = pred['labels'].cpu()\n",
        "\n",
        "                gt_box = tgt['boxes'].cpu()\n",
        "                gt_label = tgt['labels'].cpu()\n",
        "\n",
        "                all_predictions.append({'boxes': pred_box, 'scores': pred_score, 'labels': pred_label})\n",
        "                all_targets.append({'boxes': gt_box, 'labels': gt_label})\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    # Визуализация кривых валидации\n",
        "    recall_list, precision_list = compute_pr_curve(all_predictions, all_targets, iou_threshold=0.5)\n",
        "    mean_recall = np.mean(recall_list)\n",
        "    mean_precision = np.mean(precision_list)\n",
        "\n",
        "    plot_pr_curve(recall_list, precision_list, epoch+1)\n",
        "\n",
        "    return mean_recall\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(train_and_evaluate, n_trials=20)\n",
        "\n",
        "print(\"Лучшие гиперпараметры: \", study.best_params)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
